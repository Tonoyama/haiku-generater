{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 4663715354342735275,\n",
       " name: \"/device:XLA_CPU:0\"\n",
       " device_type: \"XLA_CPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 8526272000179476442\n",
       " physical_device_desc: \"device: XLA_CPU device\"]"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n",
    "\n",
    "import re\n",
    "import time\n",
    "import io\n",
    "\n",
    "from torchtext.utils import download_from_url, extract_archive\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_base = 'https://storage.googleapis.com/haiku-dataset/'\n",
    "train_urls = ('train.kigo.gz', 'train.haiku.gz')\n",
    "\n",
    "train_filepaths = [extract_archive(download_from_url(url_base + url))[0] for url in train_urls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('.data/train.kigo', mode='r', encoding='utf-8') as f:\n",
    "    kigo = f.read()\n",
    "\n",
    "with open('.data/train.haiku', mode='r', encoding='utf-8') as f:\n",
    "    haiku = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "kigo = re.sub(r'\\.(?=[0-9]|[a-z]|[A-Z])', '.###', kigo)\n",
    "kigo = re.sub(r'\\.###', '', kigo)\n",
    "kigo = re.sub(r'  +', ' ', kigo)\n",
    "kigo = kigo.split('\\n')\n",
    "\n",
    "haiku = re.sub(r'\\.(?=[0-9]|[a-z]|[A-Z])', '.###', haiku)\n",
    "haiku = re.sub(r'\\.###', '', haiku)\n",
    "haiku = re.sub(r'  +', ' ', haiku)\n",
    "haiku = haiku.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_kigo = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
    "        kigo, target_vocab_size=2**13)\n",
    "tokenizer_haiku = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
    "        haiku, target_vocab_size=2**13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE_KIGO = tokenizer_kigo.vocab_size + 2 # 2 extra spaces are for starting and ending of sentence\n",
    "VOCAB_SIZE_HAIKU = tokenizer_haiku.vocab_size + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [[VOCAB_SIZE_KIGO-2] + tokenizer_kigo.encode(sentence) + [VOCAB_SIZE_KIGO-1] for sentence in corpus_en]\n",
    "\n",
    "outputs = [[VOCAB_SIZE_HAIKU-2] + tokenizer_haiku.encode(sentence) + [VOCAB_SIZE_HAIKU-1] for sentence in corpus_fr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MAX_LENGTH = 20\n",
    "idx_to_remove = [count for count, sent in enumerate(inputs) if len(sent) > MAX_LENGTH]\n",
    "\n",
    "for idx in reversed(idx_to_remove):\n",
    "    del inputs[idx]\n",
    "    del outputs[idx]\n",
    "    \n",
    "idx_to_remove = [count for count, sent in enumerate(outputs) if len(sent) > MAX_LENGTH]\n",
    "\n",
    "for idx in reversed(idx_to_remove):\n",
    "    del inputs[idx]\n",
    "    del outputs[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.preprocessing.sequence.pad_sequences(inputs,\n",
    "                                                       value=0,\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=MAX_LENGTH)\n",
    "\n",
    "outputs = tf.keras.preprocessing.sequence.pad_sequences(outputs,\n",
    "                                                        value=0,\n",
    "                                                        padding='post',\n",
    "                                                        maxlen=MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((inputs, outputs))\n",
    "\n",
    "dataset = dataset.cache() # To increase speed\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(layers.Layer):\n",
    "    '''\n",
    "    Custom Positional Encoding Class. Inherited from tensorflow.keras.layers.Layer\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        \n",
    "    def get_angles(self, pos, i, d_model): # Input shapes -- pos: (seq_length, 1); i: (1, d_model)\n",
    "        angles = 1 / np.power(10000., (2*(i//2))/np.float32(d_model)) # Angles have even index both for odd and even indices\n",
    "        return pos * angles # Returns matrix of shape (seq_length, d_model)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        \n",
    "        seq_length = inputs.shape.as_list()[-2]\n",
    "        d_model = inputs.shape.as_list()[-1]\n",
    "        angles = self.get_angles(np.arange(seq_length)[:, np.newaxis],\n",
    "                                 np.arange(d_model)[np.newaxis, :],\n",
    "                                 d_model)\n",
    "        \n",
    "        angles[:, 0::2] = np.sin(angles[:, 0::2]) # Gives a step-size of 2 to include only even numbers\n",
    "        angles[:, 1::2] = np.cos(angles[:, 1::2]) # Gives a step-size of 2 to include only odd numbers\n",
    "        pos_encoding = angles[np.newaxis, ...] # Adding an extra dimension for batching compatibility\n",
    "        \n",
    "        return inputs + tf.cast(pos_encoding, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(queries, keys, values, mask):\n",
    "    '''\n",
    "    queries: Q Matrix\n",
    "    keys: K Matrix\n",
    "    values: V Matrix\n",
    "    mask: can be used for both look-ahead masking and masking for padded zeroes\n",
    "    '''\n",
    "    \n",
    "    product = tf.matmul(queries, keys, transpose_b=True)\n",
    "    \n",
    "    keys_dim = tf.cast(tf.shape(keys)[-1], tf.float32) # dk value\n",
    "    \n",
    "    scaled_product = product / tf.math.sqrt(keys_dim)\n",
    "    \n",
    "    if mask is not None:\n",
    "        scaled_product += (mask * -1e9) # adding a very small number for mask so that softmax value for it becomes zero\n",
    "        \n",
    "    attention = tf.matmul(tf.nn.softmax(scaled_product, axis=-1), values)\n",
    "    \n",
    "    return attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(layers.Layer):\n",
    "    '''\n",
    "    Custom Multi-head Attention Class. Inherited from tensorflow.keras.layers.Layer\n",
    "    nb_proj: Number of projections that matrices should be split into\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, nb_proj):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.nb_proj = nb_proj\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        '''\n",
    "        Runs when object if first time used. Unlike init function, which runs when the object is created\n",
    "        '''\n",
    "        \n",
    "        self.d_model = input_shape[-1] # Input Shape is the shape of Q matrix\n",
    "        assert self.d_model % self.nb_proj == 0\n",
    "        \n",
    "        self.d_proj = self.d_model //self.nb_proj\n",
    "        \n",
    "        self.query_lin = layers.Dense(units = self.d_model)\n",
    "        self.key_lin = layers.Dense(units = self.d_model)\n",
    "        self.value_lin = layers.Dense(units = self.d_model)\n",
    "        self.final_lin = layers.Dense(units = self.d_model)\n",
    "        \n",
    "    def split_proj(self, inputs, batch_size):\n",
    "        '''\n",
    "        Function for splitting input matrix into projections\n",
    "        inputs: input tensor with shape (batch_size, seq_length, d_model)\n",
    "        returns a tensor of shape(batch_size, nb_proj, seq_length, d_proj)\n",
    "        '''\n",
    "        \n",
    "        shape = (batch_size,\n",
    "                 -1,\n",
    "                 self.nb_proj,\n",
    "                 self.d_proj)\n",
    "        # print(shape, tf.shape(inputs)) --Debugging print\n",
    "        \n",
    "        splitted_inputs = tf.reshape(inputs, shape=shape) # shape of splitted_inputs: (batch_size, seq_length, nb_proj, d_proj)\n",
    "        \n",
    "        return tf.transpose(splitted_inputs, perm=[0, 2, 1, 3])\n",
    "        \n",
    "    def call(self, queries, keys, values, mask):\n",
    "        '''\n",
    "        queries: Q Matrix\n",
    "        keys: K Matrix\n",
    "        values: V Matrix\n",
    "        mask: can be used for both look-ahead masking and masking for padded zeroes\n",
    "        '''\n",
    "        batch_size = tf.shape(queries)[0]\n",
    "        \n",
    "        queries = self.query_lin(queries) # Applying Big Linear function to Q Matrix\n",
    "        keys = self.key_lin(keys) # Applying Big Linear function to K Matrix\n",
    "        values = self.value_lin(values) # Applying Big Linear function to V Matrix\n",
    "        \n",
    "        queries = self.split_proj(queries, batch_size) # Splitting into projections\n",
    "        keys = self.split_proj(keys, batch_size) # Splitting into projections\n",
    "        values = self.split_proj(values, batch_size) # Splitting into projections\n",
    "        \n",
    "        attention = scaled_dot_product_attention(queries, keys, values, mask)\n",
    "        \n",
    "        #Concatinating the splitted projections after attention in reverse process of split_proj function\n",
    "        attention = tf.transpose(attention, perm=[0, 2, 1, 3])\n",
    "        concat_attention = tf.reshape(attention,\n",
    "                                      shape=(batch_size, -1, self.d_model))\n",
    "        \n",
    "        # Applying final Linear function\n",
    "        outputs = self.final_lin(concat_attention)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(layers.Layer):\n",
    "    '''\n",
    "    Custom Encoder Layer Class. Inherited from tensorflow.keras.layers.Layer\n",
    "    FFN_units: Feed Forward Network units\n",
    "    nb_proj: Number of Projections\n",
    "    dropout: Dropout Rate\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, FFN_units, nb_proj, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.FFN_units = FFN_units\n",
    "        self.nb_proj = nb_proj\n",
    "        self.dropout = dropout\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        '''\n",
    "        Runs when object if first time used. Unlike init function, which runs when the object is created\n",
    "        '''\n",
    "        self.d_model = input_shape[-1]\n",
    "        self.multi_head_attention = MultiHeadAttention(self.nb_proj)\n",
    "        self.dropout_1 = layers.Dropout(rate=self.dropout)\n",
    "        self.norm_1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dense_1 = layers.Dense(units=self.FFN_units, activation='relu')\n",
    "        self.dense_2 = layers.Dense(units=self.d_model)\n",
    "        self.dropout_2 = layers.Dropout(rate=self.dropout)\n",
    "        self.norm_2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        \n",
    "    def call(self, inputs, mask, training):\n",
    "        attention = self.multi_head_attention(inputs,\n",
    "                                              inputs,\n",
    "                                              inputs,\n",
    "                                              mask)\n",
    "        \n",
    "        attention = self.dropout_1(attention, training=training)\n",
    "        attention = self.norm_1(attention + inputs)\n",
    "        \n",
    "        outputs = self.dense_1(attention)\n",
    "        outputs = self.dense_2(outputs)\n",
    "        outputs = self.dropout_2(outputs)\n",
    "        outputs = self.norm_2(outputs + attention)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(layers.Layer):\n",
    "    '''\n",
    "    Custom Encoder Class. Inherited from tensorflow.keras.layers.Layer\n",
    "    nb_layers: Number of layers of encoders\n",
    "    FFN_units: Feed Forward Network units\n",
    "    nb_proj: Number of Projections\n",
    "    dropout: Dropout Rate\n",
    "    vocab_size: Vocabulary Size\n",
    "    d_model: last dimension of input matrix\n",
    "    '''\n",
    "    \n",
    "    def __init__(self,\n",
    "                 nb_layers,\n",
    "                 FFN_units,\n",
    "                 nb_proj,\n",
    "                 dropout,\n",
    "                 vocab_size,\n",
    "                 d_model,\n",
    "                 name='encoder'):\n",
    "        super(Encoder, self).__init__(name=name)\n",
    "        self.nb_layers = nb_layers\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        self.embedding = layers.Embedding(vocab_size, d_model)\n",
    "        self.pos_encoding = PositionalEncoding()\n",
    "        self.dropout = layers.Dropout(rate=dropout)\n",
    "        self.enc_layers = [EncoderLayer(FFN_units,\n",
    "                                        nb_proj,\n",
    "                                        dropout)\n",
    "                           for _ in range(nb_layers)]\n",
    "        \n",
    "    def call(self, inputs, mask, training):\n",
    "        outputs = self.embedding(inputs)\n",
    "        outputs *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        outputs = self.pos_encoding(outputs)\n",
    "        outputs = self.dropout(outputs, training)\n",
    "        \n",
    "        for i in range(self.nb_layers):\n",
    "            outputs = self.enc_layers[i](outputs, mask, training)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(layers.Layer):\n",
    "    '''\n",
    "    Custom Decoder Layer Class. Inherited from tensorflow.keras.layers.Layer\n",
    "    FFN_units: Feed Forward Network units\n",
    "    nb_proj: Number of Projections\n",
    "    dropout: Dropout Rate\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, FFN_units, nb_proj, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.FFN_units = FFN_units\n",
    "        self.nb_proj = nb_proj\n",
    "        self.dropout = dropout\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        '''\n",
    "        Runs when object if first time used. Unlike init function, which runs when the object is created\n",
    "        '''\n",
    "        self.d_model = input_shape[-1]\n",
    "        \n",
    "        # Layers for Phase I\n",
    "        self.multi_head_attention_1 = MultiHeadAttention(self.nb_proj)\n",
    "        self.dropout_1 = layers.Dropout(rate=self.dropout)\n",
    "        self.norm_1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        \n",
    "        # Layers for Phase II\n",
    "        self.multi_head_attention_2 = MultiHeadAttention(self.nb_proj)\n",
    "        self.dropout_2 = layers.Dropout(rate=self.dropout)\n",
    "        self.norm_2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        \n",
    "        # Layers for Phase III\n",
    "        self.dense_1 = layers.Dense(units=self.FFN_units, activation='relu')\n",
    "        self.dense_2 = layers.Dense(units=self.d_model)\n",
    "        self.dropout_3 = layers.Dropout(rate=self.dropout)\n",
    "        self.norm_3 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        \n",
    "    def call(self, inputs, enc_outputs, mask_1, mask_2, training):\n",
    "        \n",
    "        # Phase I\n",
    "        attention = self.multi_head_attention_1(inputs,\n",
    "                                                inputs,\n",
    "                                                inputs,\n",
    "                                                mask_1)\n",
    "        attention = self.dropout_1(attention, training)\n",
    "        attention = self.norm_1(attention + inputs)\n",
    "        \n",
    "        # Phase II\n",
    "        attention_2 = self.multi_head_attention_2(attention,\n",
    "                                                enc_outputs,\n",
    "                                                enc_outputs,\n",
    "                                                mask_2)\n",
    "        attention_2 = self.dropout_2(attention_2, training)\n",
    "        attention_2 = self.norm_2(attention_2 + attention)\n",
    "        \n",
    "        # Phase III\n",
    "        outputs = self.dense_1(attention_2)\n",
    "        outputs = self.dense_2(outputs)\n",
    "        outputs = self.dropout_3(outputs, training)\n",
    "        outputs = self.norm_3(outputs + attention_2)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(layers.Layer):\n",
    "    '''\n",
    "    Custom Decoder Class. Inherited from tensorflow.keras.layers.Layer\n",
    "    nb_layers: Number of layers of decoders\n",
    "    FFN_units: Feed Forward Network units\n",
    "    nb_proj: Number of Projections\n",
    "    dropout: Dropout Rate\n",
    "    vocab_size: Vocabulary Size\n",
    "    d_model: last dimension of input matrix\n",
    "    '''\n",
    "    \n",
    "    def __init__(self,\n",
    "                 nb_layers,\n",
    "                 FFN_units,\n",
    "                 nb_proj,\n",
    "                 dropout,\n",
    "                 vocab_size,\n",
    "                 d_model,\n",
    "                 name='decoder'):\n",
    "        super(Decoder, self).__init__(name=name)\n",
    "        self.d_model = d_model\n",
    "        self.nb_layers = nb_layers\n",
    "        \n",
    "        self.embedding = layers.Embedding(vocab_size, d_model)\n",
    "        self.pos_encoding = PositionalEncoding()\n",
    "        self.dropout = layers.Dropout(rate=dropout)\n",
    "        \n",
    "        self.dec_layers = [DecoderLayer(FFN_units,\n",
    "                                        nb_proj,\n",
    "                                        dropout)\n",
    "                          for _ in range(nb_layers)]\n",
    "        \n",
    "    def call(self, inputs, enc_outputs, mask_1, mask_2, training):\n",
    "        \n",
    "        outputs = self.embedding(inputs)\n",
    "        outputs *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        outputs = self.pos_encoding(outputs)\n",
    "        outputs = self.dropout(outputs, training)\n",
    "        \n",
    "        for i in range(self.nb_layers):\n",
    "            outputs = self.dec_layers[i](outputs,\n",
    "                                         enc_outputs,\n",
    "                                         mask_1,\n",
    "                                         mask_2,\n",
    "                                         training)\n",
    "            \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    '''\n",
    "    Custom Transformer Model Class. Inherited from tensorflow.keras.Model\n",
    "    nb_layers: Number of layers of Encoders and Decoders\n",
    "    FFN_units: Feed Forward Network units\n",
    "    nb_proj: Number of Projections\n",
    "    dropout: Dropout Rate\n",
    "    vocab_size_enc: Vocabulary Size of encoder\n",
    "    vocab_size_dec: Vocabulary Size of decoder\n",
    "    d_model: last dimension of input matrix\n",
    "    '''\n",
    "    \n",
    "    def __init__(self,\n",
    "                 vocab_size_enc,\n",
    "                 vocab_size_dec,\n",
    "                 d_model,\n",
    "                 nb_layers,\n",
    "                 FFN_units,\n",
    "                 nb_proj,\n",
    "                 dropout,\n",
    "                 name='transformer'):\n",
    "        super(Transformer, self).__init__(name=name)\n",
    "        \n",
    "        self.encoder = Encoder(nb_layers,\n",
    "                               FFN_units,\n",
    "                               nb_proj,\n",
    "                               dropout,\n",
    "                               vocab_size_enc,\n",
    "                               d_model)\n",
    "        \n",
    "        self.decoder = Decoder(nb_layers,\n",
    "                               FFN_units,\n",
    "                               nb_proj,\n",
    "                               dropout,\n",
    "                               vocab_size_dec,\n",
    "                               d_model)\n",
    "        self.last_linear = layers.Dense(units = vocab_size_dec)\n",
    "        \n",
    "    \n",
    "    def create_padding_mask(self, seq):\n",
    "        '''\n",
    "        Function for creating Padding masks\n",
    "        seq: sequence of numbers post-tokenization of shape (batch_size, seq_length)\n",
    "        '''\n",
    "        mask = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "        return mask[:, tf.newaxis, tf.newaxis, :]\n",
    "    \n",
    "    def create_look_ahead_mask(self, seq):\n",
    "        '''\n",
    "        Function for creating Look Ahead masks\n",
    "        '''\n",
    "        seq_len = tf.shape(seq)[1]\n",
    "        look_ahead_mask = 1- tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "        return look_ahead_mask\n",
    "        \n",
    "    def call(self, enc_inputs, dec_inputs, training):\n",
    "        \n",
    "        enc_mask = self.create_padding_mask(enc_inputs)\n",
    "        dec_mask_1 = tf.maximum(\n",
    "                                self.create_padding_mask(dec_inputs),\n",
    "                                self.create_look_ahead_mask(dec_inputs))\n",
    "        dec_mask_2 = self.create_padding_mask(enc_inputs)\n",
    "        \n",
    "        enc_outputs = self.encoder(enc_inputs, enc_mask, training)\n",
    "        dec_outputs = self.decoder(dec_inputs,\n",
    "                                   enc_outputs,\n",
    "                                   dec_mask_1,\n",
    "                                   dec_mask_2,\n",
    "                                   training)\n",
    "        \n",
    "        outputs = self.last_linear(dec_outputs)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "#Hyper-Parameters, with article parameters given as comments\n",
    "D_MODEL = 128 # 512\n",
    "NB_LAYERS = 4 # 6\n",
    "FFN_UNITS = 512 # 2048\n",
    "NB_PROJ = 8 # 8\n",
    "DROPOUT = 0.1 # 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer(vocab_size_enc=VOCAB_SIZE_KIGO,\n",
    "                          vocab_size_dec=VOCAB_SIZE_HAIKU,\n",
    "                          d_model=D_MODEL,\n",
    "                          nb_layers=NB_LAYERS,\n",
    "                          FFN_units=FFN_UNITS,\n",
    "                          nb_proj=NB_PROJ,\n",
    "                          dropout=DROPOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True,\n",
    "                                                            reduction='none')\n",
    "\n",
    "def loss_function(target, pred):\n",
    "    '''\n",
    "    Custom loss function with no reduction and loss for padding tokens is masked to zero\n",
    "    '''\n",
    "    mask = tf.math.logical_not(tf.math.equal(target, 0))\n",
    "    loss_ = loss_object(target, pred)\n",
    "    \n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "    \n",
    "    return tf.reduce_mean(loss_)\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    '''\n",
    "    Custom Learning Rate Scheduler Class. Inherited from tensorflow.keras.optimizers.schedules.LearningRateSchedule\n",
    "    warmup_steps: steps till which learning rate is increased linearly and after which it is decreased exponentially\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "        \n",
    "        self.d_model = tf.cast(d_model, tf.float32)\n",
    "        self.warmup_steps = warmup_steps\n",
    "        \n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps**-1.5)\n",
    "        \n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "    \n",
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate,\n",
    "                                     beta_1=0.9,\n",
    "                                     beta_2=0.98,\n",
    "                                     epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Start of epoch 1\n",
      "Epoch: 1 Batch: 0 Loss: 5.4728 Accuracy: 0.0000\n",
      "Epoch: 1 Batch: 50 Loss: 5.4832 Accuracy: 0.0047\n",
      "Epoch: 1 Batch: 100 Loss: 5.4172 Accuracy: 0.0265\n",
      "Epoch: 1 Batch: 150 Loss: 5.3488 Accuracy: 0.0370\n",
      "Epoch: 1 Batch: 200 Loss: 5.2841 Accuracy: 0.0458\n",
      "Epoch: 1 Batch: 250 Loss: 5.2077 Accuracy: 0.0535\n",
      "Time taken for epoch 1: 253.77749586105347\n",
      "Start of epoch 2\n",
      "Epoch: 2 Batch: 0 Loss: 4.6495 Accuracy: 0.0855\n",
      "Epoch: 2 Batch: 50 Loss: 4.5490 Accuracy: 0.0862\n",
      "Epoch: 2 Batch: 100 Loss: 4.4561 Accuracy: 0.0875\n",
      "Epoch: 2 Batch: 150 Loss: 4.3828 Accuracy: 0.0881\n",
      "Epoch: 2 Batch: 200 Loss: 4.3266 Accuracy: 0.0883\n",
      "Epoch: 2 Batch: 250 Loss: 4.2811 Accuracy: 0.0887\n",
      "Time taken for epoch 2: 256.08761048316956\n",
      "Start of epoch 3\n",
      "Epoch: 3 Batch: 0 Loss: 3.9982 Accuracy: 0.0921\n",
      "Epoch: 3 Batch: 50 Loss: 3.9873 Accuracy: 0.0923\n",
      "Epoch: 3 Batch: 100 Loss: 3.9662 Accuracy: 0.0931\n",
      "Epoch: 3 Batch: 150 Loss: 3.9480 Accuracy: 0.0942\n",
      "Epoch: 3 Batch: 200 Loss: 3.9259 Accuracy: 0.0954\n",
      "Epoch: 3 Batch: 250 Loss: 3.9049 Accuracy: 0.0969\n",
      "Time taken for epoch 3: 256.22290992736816\n",
      "Start of epoch 4\n",
      "Epoch: 4 Batch: 0 Loss: 3.8757 Accuracy: 0.1098\n",
      "Epoch: 4 Batch: 50 Loss: 3.7302 Accuracy: 0.1123\n",
      "Epoch: 4 Batch: 100 Loss: 3.7018 Accuracy: 0.1141\n",
      "Epoch: 4 Batch: 150 Loss: 3.6876 Accuracy: 0.1153\n",
      "Epoch: 4 Batch: 200 Loss: 3.6713 Accuracy: 0.1162\n",
      "Epoch: 4 Batch: 250 Loss: 3.6577 Accuracy: 0.1172\n",
      "Time taken for epoch 4: 256.1942021846771\n",
      "Start of epoch 5\n",
      "Epoch: 5 Batch: 0 Loss: 3.5299 Accuracy: 0.1287\n",
      "Epoch: 5 Batch: 50 Loss: 3.5177 Accuracy: 0.1279\n",
      "Epoch: 5 Batch: 100 Loss: 3.5067 Accuracy: 0.1276\n",
      "Epoch: 5 Batch: 150 Loss: 3.4958 Accuracy: 0.1272\n",
      "Epoch: 5 Batch: 200 Loss: 3.4856 Accuracy: 0.1273\n",
      "Epoch: 5 Batch: 250 Loss: 3.4772 Accuracy: 0.1274\n",
      "Time taken for epoch 5: 251.25598621368408\n",
      "Start of epoch 6\n",
      "Epoch: 6 Batch: 0 Loss: 3.3529 Accuracy: 0.1287\n",
      "Epoch: 6 Batch: 50 Loss: 3.3564 Accuracy: 0.1352\n",
      "Epoch: 6 Batch: 100 Loss: 3.3559 Accuracy: 0.1341\n",
      "Epoch: 6 Batch: 150 Loss: 3.3548 Accuracy: 0.1343\n",
      "Epoch: 6 Batch: 200 Loss: 3.3461 Accuracy: 0.1346\n",
      "Epoch: 6 Batch: 250 Loss: 3.3386 Accuracy: 0.1350\n",
      "Time taken for epoch 6: 251.24022459983826\n",
      "Start of epoch 7\n",
      "Epoch: 7 Batch: 0 Loss: 3.3833 Accuracy: 0.1316\n",
      "Epoch: 7 Batch: 50 Loss: 3.2199 Accuracy: 0.1424\n",
      "Epoch: 7 Batch: 100 Loss: 3.2132 Accuracy: 0.1429\n",
      "Epoch: 7 Batch: 150 Loss: 3.2126 Accuracy: 0.1431\n",
      "Epoch: 7 Batch: 200 Loss: 3.2082 Accuracy: 0.1433\n",
      "Epoch: 7 Batch: 250 Loss: 3.2058 Accuracy: 0.1434\n",
      "Time taken for epoch 7: 244.75380611419678\n",
      "Start of epoch 8\n",
      "Epoch: 8 Batch: 0 Loss: 3.1552 Accuracy: 0.1509\n",
      "Epoch: 8 Batch: 50 Loss: 3.1014 Accuracy: 0.1510\n",
      "Epoch: 8 Batch: 100 Loss: 3.0946 Accuracy: 0.1509\n",
      "Epoch: 8 Batch: 150 Loss: 3.0926 Accuracy: 0.1510\n",
      "Epoch: 8 Batch: 200 Loss: 3.0903 Accuracy: 0.1517\n",
      "Epoch: 8 Batch: 250 Loss: 3.0882 Accuracy: 0.1523\n",
      "Time taken for epoch 8: 248.46300196647644\n",
      "Start of epoch 9\n",
      "Epoch: 9 Batch: 0 Loss: 3.0031 Accuracy: 0.1575\n",
      "Epoch: 9 Batch: 50 Loss: 2.9737 Accuracy: 0.1609\n",
      "Epoch: 9 Batch: 100 Loss: 2.9722 Accuracy: 0.1612\n",
      "Epoch: 9 Batch: 150 Loss: 2.9698 Accuracy: 0.1614\n",
      "Epoch: 9 Batch: 200 Loss: 2.9756 Accuracy: 0.1615\n",
      "Epoch: 9 Batch: 250 Loss: 2.9784 Accuracy: 0.1617\n",
      "Time taken for epoch 9: 252.2198097705841\n",
      "Start of epoch 10\n",
      "Epoch: 10 Batch: 0 Loss: 2.8710 Accuracy: 0.1690\n",
      "Epoch: 10 Batch: 50 Loss: 2.8622 Accuracy: 0.1716\n",
      "Epoch: 10 Batch: 100 Loss: 2.8616 Accuracy: 0.1707\n",
      "Epoch: 10 Batch: 150 Loss: 2.8648 Accuracy: 0.1700\n",
      "Epoch: 10 Batch: 200 Loss: 2.8674 Accuracy: 0.1697\n",
      "Epoch: 10 Batch: 250 Loss: 2.8689 Accuracy: 0.1700\n",
      "Time taken for epoch 10: 252.80271649360657\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    print(\"Start of epoch {}\".format(epoch+1))\n",
    "    start = time.time()\n",
    "    \n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    \n",
    "    for (batch, (enc_inputs, targets)) in enumerate(dataset):\n",
    "        \n",
    "        dec_inputs = targets[:, :-1]\n",
    "        dec_outputs_real = targets[:, 1:]\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = transformer(enc_inputs, dec_inputs, True)\n",
    "            loss = loss_function(dec_outputs_real, predictions)\n",
    "        \n",
    "        gradients = tape.gradient(loss, transformer.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "        \n",
    "        train_loss(loss)\n",
    "        train_accuracy(dec_outputs_real, predictions)\n",
    "        \n",
    "        if batch % 50 == 0:\n",
    "            print(\"Epoch: {} Batch: {} Loss: {:.4f} Accuracy: {:.4f}\".format(\n",
    "                epoch + 1, batch, train_loss.result(), train_accuracy.result()))\n",
    "    \n",
    "    print(\"Time taken for epoch {}: {}\".format(epoch + 1 , time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(inp_sentence):\n",
    "    inp_sentence = \\\n",
    "        [VOCAB_SIZE_KIGO-2] + tokenizer_en.encode(inp_sentence) + [VOCAB_SIZE_KIGO-1]\n",
    "    enc_input = tf.expand_dims(inp_sentence, axis=0)\n",
    "    \n",
    "    output = tf.expand_dims([VOCAB_SIZE_HAIKU-2], axis=0)\n",
    "    \n",
    "    for _ in range(MAX_LENGTH):\n",
    "        predictions = transformer(enc_input, output, False) # shape of predictions: (1, seq_length, vocab_size_fr)\n",
    "        prediction = predictions[:, -1:, :]\n",
    "        \n",
    "        predicted_id = tf.cast(tf.argmax(prediction, axis=-1), tf.int32)\n",
    "        \n",
    "        if predicted_id == VOCAB_SIZE_HAIKU-1:\n",
    "            return tf.squeeze(output, axis=0)\n",
    "        \n",
    "        output = tf.concat([output, predicted_id], axis=-1)\n",
    "        \n",
    "    return tf.squeeze(output, axis=0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sentence):\n",
    "    output = evaluate(sentence).numpy()\n",
    "    \n",
    "    predicted_sentence = tokenizer_fr.decode(\n",
    "        [i for i in output if i < VOCAB_SIZE_HAIKU-2]\n",
    "    )\n",
    "    \n",
    "    print(\"Input: {}\".format(sentence))\n",
    "    print(\"Predicted translation: {}\".format(predicted_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Input: 冬 白鳥 頸\n",
      "Predicted translation: 白鳥 の 白鳥 の 中 に 白鳥 か な\n",
      "Input: 春 菜の花 明るい\n",
      "Predicted translation: 菜の花 や 菜の花 の 中 に は の 音\n",
      "Input: 夏 恋 母\n",
      "Predicted translation: 水 の 日 の 水 に なり し 日 の 恋\n"
     ]
    }
   ],
   "source": [
    "translate(\"冬 白鳥 頸\")\n",
    "translate(\"春 菜の花 明るい\")\n",
    "translate(\"夏 恋 母\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Input: 冬 風邪\n",
      "Predicted translation: 冬 の 風邪 水 に 入る もの の 稰 か な\n",
      "Input: 春 休み\n",
      "Predicted translation: 連翹 や 海 の 中 に も ある ところ\n",
      "Input: 夏 蚊帳\n",
      "Predicted translation: 鮎 の 中 に 水 の 音 し て いる\n"
     ]
    }
   ],
   "source": [
    "translate(\"冬 風邪\")\n",
    "translate(\"春 休み\")\n",
    "translate(\"夏 蚊帳\")"
   ]
  }
 ]
}